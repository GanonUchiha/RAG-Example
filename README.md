# ğŸ§  Retrieval-Augmented Generation (RAG) with Segmented Indexing

## ğŸ”– Project Overview

This project implements a basic Retrieval-Augmented Generation (RAG) pipeline from scratch. It demonstrates how to load and process multiple documents, segment the text corpus into chunks, index the segments using FAISS, retrieve relevant segments based on a user query, and generate a response using a language model (Gemini). The project is built without using frameworks like LangChain, focusing on a ground-up implementation for learning purposes.

## ğŸ“¦ Tech Stack

| Task            | Library                 | Notes                                      |
| --------------- | ----------------------- | ------------------------------------------ |
| Text processing | `nltk`                  | For sentence tokenization                  |
| Embeddings      | `sentence-transformers` | For turning text into vectors              |
| Vector indexing | `faiss`                 | For fast retrieval                         |
| Language model  | `google.generativeai`   | Use Gemini API for answer generation       |
| Environment variables | `python-dotenv`     | For managing API keys                      |
| Python version  | `3.8+`                  | Keep the code modern and typed if possible |

## ğŸ”§ Setup Instructions

1.  **Clone the repository:**

    ```bash
    git clone <repository_url>
    cd RAG-Example
    ```

2.  **Create a virtual environment:**

    ```bash
    python -m venv .venv
    ```

3.  **Activate the virtual environment:**

    *   **Windows:**

        ```bash
        .venv\Scripts\activate
        ```

    *   **macOS/Linux:**

        ```bash
        source .venv/bin/activate
        ```

4.  **Install dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

5.  **Set up your Gemini API Key:**

    *   Obtain a Gemini API key from the Google AI Studio.
    *   Create a `.env` file in the root directory of the project.
    *   Add your API key to the `.env` file in the following format:

        ```dotenv
        GEMINI_API_KEY=YOUR_API_KEY
        ```
    *   The project uses `python-dotenv` to load this key.

## â–¶ï¸ Usage

1.  **Place your corpus files:** Put the text documents you want to use as the corpus in the `data/` directory. The project supports `.txt` and `.csv` file types.
2.  **Run the RAG pipeline:**

    ```bash
    python run_rag.py
    ```

    The `run_rag.py` script will:
    *   Load and process documents from the `data/` directory.
    *   Segment the corpus into chunks.
    *   Create a FAISS index from the chunk embeddings.
    *   Enter an interactive loop prompting you to enter a query.
    *   Retrieve the most relevant chunks based on your query.
    *   Generate an answer using the Gemini model based on the retrieved context and your query.

    Type 'quit' to exit the interactive query loop.

## ğŸ“ Project Structure

```bash
RAG-Example(root)/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ *.txt, *.csv             # Raw input documents (multiple files and types supported)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py           # Code to load and process documents from directory (handles .txt and .csv)
â”‚   â”œâ”€â”€ segmenter.py             # Code to split input text into chunks
â”‚   â”œâ”€â”€ indexer.py             # Embedding and FAISS index creation
â”‚   â”œâ”€â”€ retriever.py             # Code to query FAISS and get text chunks
â”‚   â””â”€â”€ generator.py             # Code to prompt Gemini with query+context
â”‚
â”œâ”€â”€ run_rag.py                   # Orchestrates everything end-to-end with interactive querying
â””â”€â”€ requirements.txt             # All dependencies
